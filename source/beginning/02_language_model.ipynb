{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个由 l 个词构成的句子的概率计算公式为：\n",
    "\n",
    "$$ p(s) = p(w_1)p(w_2|w_1)p(w_3|w_1 w_2)...p(w_l|w_1..w_{l-1}) \\\\\n",
    "        = \\prod_{i=1}^l p(w_i | w_1 ...w_{i-1}) \\\\\n",
    "        \\approx \\prod_{i=1}^l p(w_i | wi-1)        $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面最后一个例子是二元模型的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, defaultdict, deque, Counter\n",
    "import json\n",
    "import random \n",
    "import nltk\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: [\"It's\", 'good', 'to', 'see', 'you', 'you.']\n",
      "ngram: [(\"It's\", 'good'), ('good', 'to'), ('to', 'see'), ('see', 'you'), ('you', 'you.')]\n",
      "freq:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({(\"It's\", 'good'): 1,\n",
       "          ('good', 'to'): 1,\n",
       "          ('see', 'you'): 1,\n",
       "          ('to', 'see'): 1,\n",
       "          ('you', 'you.'): 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = \"It's good to see you you.\".split()\n",
    "words_ngram = list(ngrams(words, 2))\n",
    "words_freq = FreqDist(words_ngram)\n",
    "\n",
    "print('words:', words)\n",
    "print('ngram:', words_ngram)\n",
    "print('freq:\\n')\n",
    "words_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import jieba\n",
    "import more_itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, 'rt') as f:\n",
    "        for line in f:\n",
    "            yield line.strip()\n",
    "\n",
    "def segment_data(data):\n",
    "    \"\"\"segment data to sentence.\"\"\"\n",
    "    sentence_break = r'(。|！|？)'\n",
    "    for line in data:\n",
    "        # 按句子切分，并且捕获分组\n",
    "        sentences = re.split(sentence_break, line)\n",
    "        # 捕获的 delimiter 添加到字符串后面\n",
    "        sentences = itertools.zip_longest(sentences[0::2], \n",
    "                                          sentences[1::2],\n",
    "                                          fillvalue='')\n",
    "        sentences = (''.join(i) for i in sentences)\n",
    "        yield sentences\n",
    "\n",
    "def jieba_cut(sentences):\n",
    "    # Flat the nested iterator\n",
    "    sentences = itertools.chain.from_iterable(sentences)\n",
    "    # Clean empty sentence\n",
    "    sentences = (sentence for sentence in sentences if sentence)\n",
    "    for sentence in sentences:\n",
    "        sentence = deque(jieba.cut(sentence))\n",
    "        sentence.appendleft('$$')\n",
    "        sentence = ' '.join(sentence)\n",
    "        yield sentence\n",
    "\n",
    "def get_ngram(sentences, n=2):\n",
    "    \"\"\"Get ngram from a list of string.\"\"\"\n",
    "    for sentence in sentences:\n",
    "        ngram = ngrams(sentence.split(), n)\n",
    "        yield ngram\n",
    "        \n",
    "def count_ngram(ngram, n=2):\n",
    "    d = defaultdict(Counter)\n",
    "    for context, value in ngram:\n",
    "        d[context][value] += 1\n",
    "    return d\n",
    "\n",
    "def count_to_prob(dct):\n",
    "    prob_dct = dct.copy()\n",
    "    for context, count in prob_dct.items():\n",
    "        total = sum(count.values())\n",
    "        for word in count:\n",
    "            count[word] /= total\n",
    "    return prob_dct\n",
    "\n",
    "def generate_word(context):\n",
    "    psum = 0\n",
    "    r = random.random()\n",
    "    for word, prob in ngram_prob[context].items():\n",
    "        psum += prob\n",
    "        if psum > r:\n",
    "            return word\n",
    "\n",
    "def generate_sentence(word):\n",
    "    while word:\n",
    "        word = generate_word(word)\n",
    "        yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/df/g_gpcyqx3j35s2yvr5k2tysc0000gn/T/jieba.cache\n",
      "Loading model cost 1.050 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "data = read_data('data/YGZ-rain.md')\n",
    "sentences = segment_data(data)\n",
    "sentences = jieba_cut(sentences)\n",
    "ngram = itertools.chain.from_iterable(get_ngram(sentences, n=2))\n",
    "ngram_counts = count_ngram(ngram)\n",
    "ngram_prob = count_to_prob(ngram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "而究竟在伞上尝凉凉甜甜的雨水，等他听台风台雨在虚无之间罢了。\n"
     ]
    }
   ],
   "source": [
    "g_sentence = generate_sentence('$$')\n",
    "sentence = ''.join(more_itertools.islice_extended(g_sentence, 0, -1))\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 个词时候的探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', \"don't\", 'master'),\n",
       " (\"don't\", 'master', 'regular'),\n",
       " ('master', 'regular', 'expression'),\n",
       " ('regular', 'expression', \"don't\"),\n",
       " ('expression', \"don't\", 'master'),\n",
       " (\"don't\", 'master', 'regular'),\n",
       " ('master', 'regular', 'expression')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = list(ngrams(\"I don't master regular expression don't master regular expression\".split(), 3))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"don't\"] master\n",
      "[\"don't\", 'master'] regular\n",
      "['master', 'regular'] expression\n",
      "['regular', 'expression'] don't\n",
      "['expression', \"don't\"] master\n",
      "[\"don't\", 'master'] regular\n",
      "['master', 'regular'] expression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(collections.Counter,\n",
       "            {('I', \"don't\"): Counter({'master': 1}),\n",
       "             (\"don't\", 'master'): Counter({'regular': 2}),\n",
       "             ('expression', \"don't\"): Counter({'master': 1}),\n",
       "             ('master', 'regular'): Counter({'expression': 2}),\n",
       "             ('regular', 'expression'): Counter({\"don't\": 1})})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = defaultdict(Counter)\n",
    "for *i, j in test:\n",
    "    d[tuple(i)][j] += 1\n",
    "    print(i, j)\n",
    "    \n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平滑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平滑的应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
