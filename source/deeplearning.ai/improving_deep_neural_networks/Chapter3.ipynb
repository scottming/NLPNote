{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 调试处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何系统地组织超参数调试过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有一些超参数比其他超参数更重要，比如最重要的就是学习率 $\\alpha$\n",
    "\n",
    "1. 最重要\n",
    "    * $\\alpha$\n",
    "2. 次级重要\n",
    "    * hidden units\n",
    "    * mini-batch size\n",
    "    * $\\beta$ 0.9\n",
    "3. 三级重要\n",
    "    * layers\n",
    "    * learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何调试：\n",
    "\n",
    "* 原则 1：Try random values: Don't use a grid，因为对于你要解决的问题而言，你很难提前知道哪个超参数最重要。\n",
    "* 惯例 2：粗糙到精细(Coarse to fine)，比如如果在一个小的区域比较好，那么可以放大这个区域，集中在这个区域取值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 为超参数选择合适的范围"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机取值并不是在有效范围内的随机均匀取值，而是需要选择合适的标尺。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机均匀取值并不适用于超参数，比如 $\\alpha$ 从 0.0001 到 1，这样会让小的值占用的太少搜索空间，反而用对数搜索会好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012920342123378678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "r = -4 * np.random.rand()  # r <- [-4, 0]\n",
    "alpha = 10**r\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结一下，在对数轴上取值，取最小值的对数就得到 a 值，取最大值的对数就得到 b 值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于 $\\beta$ 的取值**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta = 0.9 ... 0.999$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记住一点，取 0.9 就是在 10个值里面取平均，而去 0.999 就是在 1000 个值里面取平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么我们探究的是 $1-\\beta$ 的值，是在 0.1 ... 0.001 的大小，所以 类似于 $\\alpha$ 的取值方法，$r \\in [-3, -1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 超参数的实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于超参数的设定，有两个不同的流派"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Babysitting one model 照看，观察，调整，当没有足够计算资源，且不能再同一时间试验大量模型时才采取的办法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种方式是 Training many modeles in parallel，观察各自的学习曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种区别就像是熊宝宝和鱼类繁殖"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 正则化网络的激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch 归一化思想，让参数搜索更加容易，使神经网络对超参数的选择更加稳定。超参数的范围会更庞大，工作效果也很好，也会使你很容易的训练甚至是深层网络。\n",
    "\n",
    "对于深层网络，我们能否归一化 a 值？\n",
    "\n",
    "这就是 batch 归一化，但我们实际上归一化的不是 $a^{[2]}$，而是 $z^{[2]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tilde{Z} = yZ_{norm}^{(i)} + \\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会更新 $y$ 和 $\\beta$，正如神经网络的权重一样。\n",
    "\n",
    "$y$ 和 $\\beta$ 的作用是你可以随意设置 $\\tilde z$ 的平均值\n",
    "\n",
    "batch 归一化的作用是它适用的不只是输入层，同样也适用于神经网络中的深度隐层。\n",
    "\n",
    "不过训练输入和这些隐藏单元值的一个区别是，你也许不想隐藏单元值必须是平均值0和方差1，比如 sigmoid 函数，想让他们有更大的方差。有了 $y$ 和 $\\beta$ 之后，你可以确保所有的 $z^{i}$ 可以是你想赋予的任何值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 将 batch norm 应用于神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta$ 和 另外的指数平均的 $\\beta$ 没有任何关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里改天看下 Tensorflow 的源码以及做下作业，加深下印象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Why does batch norm work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch 归一化之后，以获得类似范围的值，可以加速学习，Batch 归一化有效的第二个原因是，他可以使得权重比你的网络更滞后或更深层，更经受的住变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch 归一化可以和 dropout 一起使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "较大的 mini-batch 会减少正则化的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不要把 batch 归一化当成正则化，而是一种加速学习的方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 测试时的 batch norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了将你的神经网络运用于测试，就需要单独估算 $\\mu$ 和 $\\sigma ^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这章看理论没怎么看懂，空了试试作业和代码，或看下原始论文。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  softmax 衡量的是每一个节点输出的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个激活函数不一样的地方在于，这个函数 g 需要输入一个 4\\*1 维向量，然后输出一个 4\\*1 维的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.  训练一个 softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 C 为 2 的时候，实际上 softmax 变回了 logistic Regression\n",
    "\n",
    "有空再看看这里的训练推导。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 选择框架的标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing deep learning frameworks**\n",
    "\n",
    "* Ease of programming\n",
    "* Running speed\n",
    "* Truly open(不仅需要开源，而且需要良好的管理)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
